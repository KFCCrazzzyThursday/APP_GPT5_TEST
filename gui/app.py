# -*- coding: utf-8 -*-
import json
import os
import tkinter as tk
from tkinter import ttk, filedialog, messagebox
from pathlib import Path
from datetime import datetime

from config import DEFAULT_BATCH_SIZE, DEFAULT_CHECKPOINT_EVERY, MODEL_NAME
from api_client import setup_client

from extractor.pdf_extract import extract_pdf, DEFAULT_LAYOUT
from enrich.enrich import enrich_file
from study.srs import score_priority, update, DEFAULT_SRS, ensure
from study.grader import grade_with_llm   # ä»ä¿ç•™ Study é¡µä½¿ç”¨
from study.sampler import weighted_sample_without_replacement, anti_repeat_filter, mark_scheduled
from agent.propose import propose_from_text
from utils.jsonio import dump_json_atomic, load_json
from .widgets import LineEntry, LogBox, ProgBar, Worker

CHAT_DIR = Path("data/chats")
CHAT_DIR.mkdir(parents=True, exist_ok=True)

# ---------------- å°å·¥å…· ----------------




def _normalize_query_word(w: str) -> str:
    if not w: return w
    wl = w.strip().lower()
    if len(wl) > 3 and wl.endswith("ies"): return wl[:-3] + "y"
    if len(wl) > 2 and wl.endswith("es"): return wl[:-2]
    if len(wl) > 2 and wl.endswith("s"): return wl[:-1]
    return wl


def _must_pick_store_or_raise(entry_widget: LineEntry) -> Path:
    p = (entry_widget.get() or "").strip()
    if not p: raise RuntimeError("è¯·å…ˆé€‰æ‹©è¯åº“ JSONï¼ˆenriched.jsonï¼‰åå†èŠå¤©æˆ–å†™åº“ã€‚")
    path = Path(p)
    if path.is_dir(): raise RuntimeError(f"é€‰æ‹©çš„æ˜¯ç›®å½•ï¼š{path}ã€‚è¯·é€‰ä¸­ä¸€ä¸ª .json æ–‡ä»¶ã€‚")
    if path.suffix.lower() != ".json": raise RuntimeError(
        f"è¯åº“æ–‡ä»¶éœ€è¦æ˜¯ .jsonï¼Œå½“å‰ï¼š{path}")
    path.parent.mkdir(parents=True, exist_ok=True)
    return path


def _trim_messages(messages, max_len=60):
    # åªä¿ç•™æœ€å max_len æ¡ï¼Œé¿å…ä¸Šä¸‹æ–‡è¿‡é•¿
    return messages[-max_len:]

# ---------------- ä¸»åº”ç”¨ ----------------


class App(tk.Tk):
    def __init__(self):
        super().__init__()
        self.title("Vocab Suite")
        self.geometry("1180x780")
        nb = ttk.Notebook(self); nb.pack(fill="both", expand=True)

        # é¡ºåºï¼šChat ä¼˜å…ˆ
        self.tab_chat = ttk.Frame(nb); nb.add(
            self.tab_chat, text="0) Chat (ä¸»æ¨¡å¼)")
        self.tab_extract = ttk.Frame(nb); nb.add(
            self.tab_extract, text="1) Extract PDF")
        self.tab_enrich = ttk.Frame(nb); nb.add(
            self.tab_enrich,  text="2) Enrich")
        self.tab_study = ttk.Frame(nb); nb.add(
            self.tab_study,   text="3) Study")

        self._build_chat()
        self._build_extract()
        self._build_enrich()
        self._build_study()

    # ---------------- Chat ----------------
    def _redact_for_log(self, payload):
        """
        æ·±åº¦è„±æ•ï¼šéšè—ä¸­æ–‡é‡Šä¹‰å­—æ®µï¼Œé¿å…åœ¨æ—¥å¿—é‡Œå‰§é€ã€‚
        - ä»»ä½•åä¸º 'meaning_zh' çš„é”®ç½®ä¸º '[hidden]'
        - ä»»ä½•åä¸º 'zh' çš„é”®ç½®ä¸º '[hidden]'
        - 'example' ä¸‹çš„ 'zh' ä¹Ÿä¼šè¢«éšè—
        """
        import copy
        if not self.var_hide_answers.get():
            return payload

        def _walk(x):
            if isinstance(x, dict):
                out = {}
                for k, v in x.items():
                    if k in ("meaning_zh", "zh"):
                        out[k] = "[hidden]"
                    elif k == "example" and isinstance(v, dict):
                        vv = v.copy()
                        if "zh" in vv:
                            vv["zh"] = "[hidden]"
                        out[k] = _walk(vv)
                    else:
                        out[k] = _walk(v)
                return out
            if isinstance(x, list):
                return [_walk(i) for i in x]
            return x
        return _walk(copy.deepcopy(payload))

    def _build_chat(self):
        f = self.tab_chat

        root = ttk.Frame(f)
        root.pack(fill="both", expand=True)
        # å·¦ä¾§ï¼šä¼šè¯åˆ—è¡¨ & æ“ä½œï¼ˆä¿æŒä½ ç°æœ‰é€»è¾‘ï¼‰
        left = ttk.Frame(root, width=260)
        left.pack(side="left", fill="y")
        ops = ttk.Frame(left)
        ops.pack(fill="x", padx=8, pady=8)
        ttk.Button(ops, text="æ–°å»ºä¼šè¯", command=self._new_chat).pack(
            side="left", padx=4)
        ttk.Button(ops, text="ä¿å­˜ä¼šè¯", command=self._save_chat).pack(
            side="left", padx=4)
        ttk.Button(ops, text="åˆ·æ–°åˆ—è¡¨", command=self._refresh_chat_list).pack(
            side="left", padx=4)
        self.lst_chats = tk.Listbox(left, height=28)
        self.lst_chats.pack(fill="both", expand=True, padx=8, pady=4)
        self.lst_chats.bind("<<ListboxSelect>>", self._on_select_chat)

        # å³ä¾§ï¼šèŠå¤©åŒºåŸŸ
        right = ttk.Frame(root)
        right.pack(side="left", fill="both", expand=True)

        # è¯åº“è·¯å¾„
        self.e_store = LineEntry(right, "è¯åº“ JSON (enriched)")
        self.e_store.pack(fill="x", padx=10, pady=6)
        ttk.Button(right, text="é€‰æ‹©è¯åº“", command=lambda: self._pick_json(
            self.e_store)).pack(padx=10, pady=2, anchor="w")

        # ä¼šè¯æ˜¾ç¤ºï¼ˆå†å²æ¶ˆæ¯ï¼‰
        frm = ttk.Frame(right)
        frm.pack(fill="both", expand=True, padx=10, pady=6)
        self.txt_chat = tk.Text(frm, height=18, wrap="word")
        self.txt_chat.pack(side="left", fill="both", expand=True)
        y = ttk.Scrollbar(frm, orient="vertical", command=self.txt_chat.yview)
        y.pack(side="right", fill="y")
        self.txt_chat.config(yscrollcommand=y.set)

        # å·¥å…·æ—¥å¿—çš„é€‰é¡¹ï¼ˆéšè—ç­”æ¡ˆã€æŠ˜å æ—¥å¿—ï¼‰
        opts = ttk.Frame(right)
        opts.pack(fill="x", padx=10, pady=2)
        self.var_hide_answers = tk.BooleanVar(value=True)
        ttk.Checkbutton(opts, text="éšè—å‚è€ƒç­”æ¡ˆ(meaning_zh/zh)",
                        variable=self.var_hide_answers).pack(side="left")
        self.var_fold_log = tk.BooleanVar(value=False)

        def _toggle_log():
            if self.var_fold_log.get():
                self.log_tools.pack_forget()
            else:
                self.log_tools.pack(fill="x", padx=10, pady=4)
        ttk.Checkbutton(opts, text="æŠ˜å å·¥å…·æ—¥å¿—", variable=self.var_fold_log,
                        command=_toggle_log).pack(side="left", padx=12)

        # å·¥å…·è°ƒç”¨æ—¥å¿—
        self.log_tools = LogBox(right)
        self.log_tools.pack(fill="x", padx=10, pady=4)

        # è¾“å…¥åŒºï¼ˆå¤šè¡Œ Text + åŠ¨æ€é«˜åº¦ + æ»šåŠ¨æ¡ï¼‰
        entry_row = ttk.Frame(right)
        entry_row.pack(fill="x", padx=10, pady=6)
        input_wrap = ttk.Frame(entry_row)
        input_wrap.pack(side="left", fill="x", expand=True)

        self.txt_input = tk.Text(input_wrap, height=1, wrap="word", undo=True)
        self.txt_input.pack(side="left", fill="x", expand=True)
        # åªåœ¨è¡Œæ•°>5æ—¶æ˜¾ç¤º
        self.in_scroll = ttk.Scrollbar(
            input_wrap, orient="vertical", command=self.txt_input.yview)
        self.txt_input.configure(yscrollcommand=lambda *args: None)  # æˆ‘ä»¬æ‰‹åŠ¨æ§åˆ¶æ˜¾éš

        # ç»‘å®šé”®ä½ï¼šEnter å‘é€ã€Shift+Enter æ¢è¡Œã€é”®é‡Šæ”¾åè‡ªé€‚åº”é«˜åº¦
        self.txt_input.bind("<Return>", self._on_input_return)
        self.txt_input.bind("<Shift-Return>", self._on_input_shift_return)
        self.txt_input.bind("<KeyRelease>", self._on_input_keyrelease)

        ttk.Button(entry_row, text="å‘é€", command=self._chat_send).pack(
            side="left", padx=6)

        # LLM ä¸å·¥å…·
        self.client = setup_client()
        self.tools = self._tool_specs()

        # ä¼šè¯å†å²ï¼ˆæŒä¹…åŒ– & æ–°å»º/ä¿å­˜ï¼‰â€”â€”ä¿æŒä½ ä¹‹å‰çš„å®ç°
        self.chat_history = self._initial_system_messages()
        self.current_chat_path = None
        self._refresh_chat_list()
        self._new_chat()


    def _initial_system_messages(self):
        return [
            {"role":"system","content":(
                "You are an English vocabulary tutor and study coach.\n"
                "STYLE:\n"
                "- Default to ENGLISH unless the user writes mostly in Chinese.\n"
                "- Be concise, friendly, and interactive like a real tutor.\n"
                "- DO NOT reveal Chinese translations or answers unless the user says "
                "\"show answer\" or after they have attempted/declined.\n"
                "- Prefer short English hints (definition clues, synonyms, collocations) before revealing any answer.\n"
                "\n"
                "TOOLS POLICY:\n"
                "- Dictionary/KB management via tools; do not print tool JSON in normal replies.\n"
                "- When the user asks to \"study\" or \"test\" N words: call sample_study_items(k=N). "
                "For each word: 1) Ask if they remember it (y/n); 2) Ask them to write an English sentence using the word; "
                "3) Call grade_usage(word, sentence) to score and produce short feedback; 4) Call update_srs(word, score_0_1).\n"
                "- When adding/amending notes, confusions, phrases, etc., call the corresponding tool.\n"
                "- If the user asks for the translation explicitly (e.g., \"show answer\"), you may reveal it.\n"
            )}
        ]


    def _pick_json(self, entry: LineEntry):
        p = filedialog.askopenfilename(
            title="é€‰æ‹© JSON", filetypes=[("JSON", ".json")])
        if p: entry.set(p)

    # ---- ä¼šè¯å­˜å– ----
    def _refresh_chat_list(self):
        self.lst_chats.delete(0, "end")
        files = sorted(CHAT_DIR.glob("*.json"),
                       key=lambda p: p.stat().st_mtime, reverse=True)
        for p in files:
            self.lst_chats.insert("end", p.name)

    def _new_chat(self):
        # æ¸…ç©ºçª—å£ä¸å†å²ï¼Œå»ºç«‹æ–°çš„æœªå‘½åä¼šè¯
        self.txt_chat.delete("1.0", "end")
        self.txt_chat.insert("end", "ï¼ˆæ–°ä¼šè¯å·²åˆ›å»ºï¼‰\n")
        self.chat_history = self._initial_system_messages()
        self.current_chat_path = None

    def _save_chat(self):
        # ç¬¬ä¸€å¥ç”¨æˆ·å†…å®¹åšæ ‡é¢˜
        title = "chat"
        for m in self.chat_history:
            if m["role"] == "user":
                title = (m["content"] or "chat").strip().splitlines()[0][:40]
                break
        ts = datetime.now().strftime("%Y%m%d_%H%M%S")
        fname = f"{ts}_{title}.json"
        path = CHAT_DIR / fname
        path.write_text(json.dumps(self.chat_history,
                        ensure_ascii=False, indent=2), encoding="utf-8")
        self.current_chat_path = path
        self._refresh_chat_list()
        messagebox.showinfo("å·²ä¿å­˜", f"å·²ä¿å­˜åˆ° {path}")

    def _on_select_chat(self, evt):
        try:
            sel = self.lst_chats.curselection()
            if not sel: return
            name = self.lst_chats.get(sel[0])
            path = CHAT_DIR / name
            data = json.loads(path.read_text(encoding="utf-8"))
            self.chat_history = data
            self.current_chat_path = path
            # åœ¨çª—å£é‡Œæ¸²æŸ“æœ€è¿‘è‹¥å¹²æ¡æ¶ˆæ¯
            self.txt_chat.delete("1.0", "end")
            for m in data[-40:]:
                if m["role"] == "user":
                    self.txt_chat.insert("end", f"[ä½ ] {m['content']}\n")
                elif m["role"] == "assistant":
                    self.txt_chat.insert(
                        "end", f"[åŠ©æ‰‹] {m.get('content','')}\n")
            self.txt_chat.see("end")
        except Exception as ex:
            messagebox.showerror("é”™è¯¯", f"åŠ è½½ä¼šè¯å¤±è´¥ï¼š{ex}")

    # ==== è¾“å…¥æ¡†ï¼ˆChatï¼‰è¾…åŠ©ï¼šå–æ–‡æœ¬ã€æ¸…ç©ºã€åŠ¨æ€é«˜åº¦ã€é”®ç›˜ç»‘å®š ====
    def _input_get(self) -> str:
        try:
            return self.txt_input.get("1.0", "end-1c")
        except Exception:
            return ""

    def _input_clear(self):
        try:
            self.txt_input.delete("1.0", "end")
            # é‡ç½®é«˜åº¦åˆ° 1 è¡Œ
            self.txt_input.configure(height=1)
            # éšè—æ»šåŠ¨æ¡
            if hasattr(self, "in_scroll"):
                self.in_scroll.pack_forget()
        except Exception:
            pass

    def _adjust_input_height(self, *_):
        """
        æ ¹æ®å½“å‰å†…å®¹è¡Œæ•°è‡ªåŠ¨è°ƒæ•´è¾“å…¥æ¡†é«˜åº¦ï¼ˆ1~5 è¡Œï¼‰ï¼Œè¶…è¿‡ 5 è¡Œæ˜¾ç¤ºæ»šåŠ¨æ¡ã€‚
        """
        try:
            # å½“å‰å†…å®¹çš„è¡Œæ•°
            lines = int(self.txt_input.index("end-1c").split(".")[0])
            new_h = max(1, min(5, lines))
            if int(self.txt_input.cget("height")) != new_h:
                self.txt_input.configure(height=new_h)

            # è¶…è¿‡ 5 è¡Œæ˜¾ç¤ºæ»šåŠ¨æ¡ï¼Œå¦åˆ™éšè—
            if lines > 5:
                if not getattr(self, "_in_scroll_shown", False):
                    self.in_scroll.pack(side="right", fill="y")
                    self._in_scroll_shown = True
            else:
                if getattr(self, "_in_scroll_shown", False):
                    self.in_scroll.pack_forget()
                    self._in_scroll_shown = False
        except Exception:
            pass

    def _on_input_return(self, event):
        """
        å›è½¦å‘é€ï¼ˆé˜»æ­¢é»˜è®¤æ¢è¡Œï¼‰
        """
        self._chat_send()
        return "break"

    def _on_input_shift_return(self, event):
        """
        Shift+Enter = æ’å…¥æ¢è¡Œ
        """
        try:
            self.txt_input.insert("insert", "\n")
            self._adjust_input_height()
        except Exception:
            pass
        return "break"

    def _on_input_keyrelease(self, event):
        """
        ä»»æ„é”®é‡Šæ”¾åï¼Œå°è¯•è°ƒæ•´é«˜åº¦ï¼ˆé¿å…æŒ‰é”®è¿‡ç¨‹ä¸­å¤šæ¬¡é‡ç»˜ï¼‰
        """
        self._adjust_input_height()

    # ---- å·¥å…·å®šä¹‰ ----
    def _tool_specs(self):
        return [
            {"type": "function", "function": {
                "name": "get_word", "description": "æŒ‰è‹±æ–‡å•è¯ç²¾ç¡®æŸ¥è¯¢è¯æ¡ï¼›å¸¦å¾®å¼±è¯å½¢å½’ä¸€ã€‚",
                "parameters": {"type": "object", "properties": {"word": {"type": "string"}}, "required": ["word"]}
            }},
            {"type": "function", "function": {
                "name": "upsert_word", "description": "è‹¥è¯æ¡ä¸å­˜åœ¨æˆ–é‡Šä¹‰ä¸å®Œæ•´åˆ™ enrich åå†™å…¥ï¼›å¯è¿½åŠ æ¥æºä¸å¤‡æ³¨ã€‚",
                "parameters": {"type": "object", "properties": {
                    "word": {"type": "string"}, "meaning_hint": {"type": "string"},
                    "source": {"type": "string"}, "note": {"type": "string"},
                    "tags": {"type": "array", "items": {"type": "string"}}
                }, "required": ["word"]}}
            },
            {"type": "function", "function": {
                "name": "update_user_note", "description": "ä¸ºå•è¯è¿½åŠ ä¸€æ¡ç”¨æˆ·æ³¨æ„äº‹é¡¹ã€‚",
                "parameters": {"type": "object", "properties": {
                    "word": {"type": "string"}, "append_note": {"type": "string"}
                }, "required": ["word", "append_note"]}}
            },
            {"type": "function", "function": {
                "name": "log_confusion", "description": "è®°å½•ä¸å¦ä¸€ä¸ªå•è¯çš„æ··æ·†åŠåŒºåˆ†æç¤ºã€‚",
                "parameters": {"type": "object", "properties": {
                    "word": {"type": "string"}, "confused_with": {"type": "string"}, "tip_zh": {"type": "string"}
                }, "required": ["word", "confused_with"]}}
            },
            {"type": "function", "function": {
                "name": "add_phrase", "description": "ä¸ºå•è¯æ·»åŠ å¸¸ç”¨çŸ­è¯­/æ­é…ã€‚",
                "parameters": {"type": "object", "properties": {
                    "word": {"type": "string"}, "phrase": {"type": "string"}, "meaning_zh": {"type": "string"}
                }, "required": ["word", "phrase"]}}
            },
            {"type": "function", "function": {
                "name": "search_words", "description": "æŒ‰å­ä¸²æˆ–æ ‡ç­¾æœç´¢è¯æ¡ã€‚",
                "parameters": {"type": "object", "properties": {
                    "query": {"type": "string"}, "tag": {"type": "string"}, "limit": {"type": "integer", "default": 20}
                }}}
            },
            {"type": "function", "function": {
                "name": "set_attr", "description": "è®¾ç½®è¯æ¡ä»»æ„å±æ€§ï¼ˆå¦‚ model_notes/priority_boostï¼‰ã€‚",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "word": {"type": "string"},
                        "key": {"type": "string"},
                        "value": {
                            "anyOf": [
                                {"type": "string"},
                                {"type": "number"},
                                {"type": "boolean"},
                                {"type": "null"},
                                {"type": "object", "additionalProperties": {}},
                                {"type": "array", "items": {}}
                            ]
                        }
                    },
                    "required": ["word", "key", "value"]
                }
            }},
            # === æ–°å¢ï¼šæŒ‰é‡è¦æ€§Ã—è¦†ç›–ä¿éšœ åŠ æƒæŠ½æ ·æµ‹éªŒ ===
            {"type": "function", "function": {
                "name": "sample_study_items", "description": "ä»è¯åº“åŠ æƒæŠ½æ ·è‹¥å¹²è¯ç”¨äºæµ‹éªŒï¼Œè‡ªåŠ¨å†™å›è°ƒåº¦è®¡æ•°ä¸æ—¶é—´ã€‚",
                "parameters": {"type": "object", "properties": {
                    "k": {"type": "integer", "minimum": 1, "maximum": 100, "default": 20},
                    "min_days_gap": {"type": "number", "minimum": 0, "default": 1.0}
                }, "required": []}
            }},
            # === æ–°å¢ï¼šæ›´æ–° SRSï¼ˆä¾›æ¨¡å‹åœ¨æµ‹éªŒåè°ƒç”¨ï¼‰===
            {"type": "function", "function": {
                "name": "update_srs", "description": "æ ¹æ®è¯„åˆ†æ›´æ–°æŒ‡å®šå•è¯çš„ SRSã€‚",
                "parameters": {"type": "object", "properties": {
                    "word": {"type": "string"},
                    "score_0_1": {"type": "number", "minimum": 0, "maximum": 1}
                }, "required": ["word", "score_0_1"]}}
            },
            {"type": "function", "function": {
                "name": "grade_usage",
                "description": "Grade the user's example sentence for a given word and return a structured score and short feedback in English.",
                "parameters": {"type": "object", "properties": {
                    "word": {"type": "string"},
                    "sentence": {"type": "string"}
                }, "required": ["word", "sentence"]}
            }},

            {"type": "function", "function": {
                "name": "propose_words_from_text", "description": "ä»é•¿æ–‡æœ¬ä¸­æŒ‘é€‰å€¼å¾—å­¦ä¹ çš„å€™é€‰è¯å¹¶ç»™å‡ºç†ç”±ã€‚",
                "parameters": {"type": "object", "properties": {
                    "source": {"type": "string"},
                    "candidates": {"type": "array", "items": {"type": "object", "properties": {
                        "word": {"type": "string"}, "reason": {"type": "string"}, "difficulty_1_5": {"type": "integer"}},
                        "required": ["word"]}},
                    "tags": {"type": "array", "items": {"type": "string"}}
                }, "required": ["candidates"]}}
            }
        ]

    # ---- å·¥å…·æ‰§è¡Œé€»è¾‘ ----
    def _apply_tool(self, name: str, args: dict):
        store_path = _must_pick_store_or_raise(self.e_store)
        store = load_json(store_path)
        self.log_tools.log(
            f"[tool-call] {json.dumps({'name':name,'args':args}, ensure_ascii=False)}")

        def norm_entry(e: dict):
            e.setdefault("word", ""); e.setdefault("meaning_zh", "")
            e.setdefault("pos", ""); e.setdefault("synonyms_en", [])
            e.setdefault("phrases", []); e.setdefault(
                "example", {"en": "", "zh": ""})
            e.setdefault("confusions", []); e.setdefault("model_notes", "")
            e.setdefault("user_notes", []); e.setdefault(
                "tags", []); e.setdefault("sources", [])
            e.setdefault("srs", dict(DEFAULT_SRS)); e.setdefault(
                "sched", {"times_scheduled": 0})
            return e

        def find_idx(w: str):
            wl = (w or "").strip().lower()
            entries = store.get("entries", [])
            for i, e in enumerate(entries):
                if (e.get("word") or "").lower() == wl: return i
            base = _normalize_query_word(wl)
            if base != wl:
                for i, e in enumerate(entries):
                    if (e.get("word") or "").lower() == base: return i
            return -1

        # ---- ç°æœ‰å·¥å…·ï¼ˆç•¥å¾®çœç•¥é‡å¤ä»£ç ï¼Œé€»è¾‘åŒå‰ç‰ˆæœ¬ï¼‰----
        if name == "get_word":
            w= args.get("word", ""); idx = find_idx(w)
            res = {"found": idx != -1, "entry": store["entries"][idx] if idx != -1 else None}
            self.log_tools.log(
                f"[tool-ret ] {json.dumps(res, ensure_ascii=False)}")
            return res

        if name == "upsert_word":
            from enrich.enrich import enrich_one as _enrich_one
            w= args.get("word", "") or ""
            wnorm = _normalize_query_word(w)
            hint= args.get("meaning_hint", "") or ""
            src = args.get("source", "chat"); note = args.get("note", "") or ""
            tags= args.get("tags", []) or []
            idx = find_idx(wnorm)
            if idx == -1:
                enriched = _enrich_one(wnorm, hint); e = norm_entry(enriched)
                if src: e["sources"].append(src)
                if note: e["user_notes"].append(note)
                for t in tags:
                    if t not in e["tags"]: e["tags"].append(t)
                store.setdefault("entries", []).append(e)
            else:
                e = norm_entry(store["entries"][idx])
                if not e.get("meaning_zh"):
                    enriched = _enrich_one(e.get("word", ""), e.get("meaning_zh", ""))
                    for k in ["meaning_zh", "pos", "synonyms_en", "phrases", "example", "confusions", "model_notes"]:
                        if k in enriched and enriched[k]: e[k]= enriched[k]
                if src and src not in e["sources"]: e["sources"].append(src)
                if note: e["user_notes"].append(note)
                store["entries"][idx] = e
            store.setdefault("meta", {})["count"] = len(store["entries"])
            dump_json_atomic(store_path, store)
            res = {"ok": True}
            self.log_tools.log(
                f"[tool-ret ] {json.dumps(self._redact_for_log(res), ensure_ascii=False)}")

            return res
        if name == "grade_usage":
            w = args.get("word",""); sent = (args.get("sentence","") or "").strip()
            idx = find_idx(w)
            if idx == -1:
                res = {"ok": False, "error": "not found"}
                self.log_tools.log(f"[tool-ret ] {json.dumps(self._redact_for_log(res), ensure_ascii=False)}")
                return res
            # ç»„è£… cardï¼ˆä¼ ç»™ LLM è¯„åˆ†å™¨ï¼‰
            e = store["entries"][idx]
            card = {
                "word": e.get("word",""),
                "meaning_zh": e.get("meaning_zh",""),
                "pos": e.get("pos",""),
                "synonyms_en": e.get("synonyms_en",[]),
                "phrases": e.get("phrases",[]),
                "example": e.get("example",{"en":"","zh":""}),
                "confusions": e.get("confusions",[]),
                "model_notes": e.get("model_notes","")
            }
            from study.grader import grade_with_llm
            result = grade_with_llm("example_usage", card, sent, retry=1, force_tool=True)
            # é™„ä¸ŠçŸ­è¯„ï¼ˆè‹±æ–‡ï¼Œæ–¹ä¾¿æ¨¡å‹å¤è¿°ï¼‰
            score = float(result.get("score_0_1", 0.0))
            mistakes = result.get("mistakes",[])
            correction = result.get("correction","")
            expl = result.get("explanation","")
            short_fb = f"Score: {score:.2f}. " \
                    f"{('Issues: ' + '; '.join(mistakes) + '. ') if mistakes else ''}" \
                    f"{('Correction: ' + correction + '. ') if correction else ''}" \
                    f"{('Note: ' + expl) if expl else ''}"
            res = {"ok": True, "score_0_1": score, "short_feedback_en": short_fb, "raw": result}
            self.log_tools.log(f"[tool-ret ] {json.dumps(self._redact_for_log(res), ensure_ascii=False)}")
            return res

        if name == "update_user_note":
            w = args.get("word", ""); ap = args.get("append_note", "") or ""
            idx = find_idx(w)
            if idx == -1:
                res= {"ok": False, "error": "not found"}
            else:
                e = norm_entry(store["entries"][idx]); e["user_notes"].append(ap)
                store["entries"][idx]= e; dump_json_atomic(store_path, store); res = {"ok": True}
            self.log_tools.log(f"[tool-ret ] {json.dumps(res, ensure_ascii=False)}"); return res

        if name == "log_confusion":
            w= args.get("word", ""); cw = args.get("confused_with", ""); tip = args.get("tip_zh", "") or ""
            idx = find_idx(w)
            if idx == -1:
                res= {"ok": False, "error": "not found"}
            else:
                e= norm_entry(store["entries"][idx]); e["confusions"].append({"with": cw, "tip_zh": tip})
                store["entries"][idx]= e; dump_json_atomic(store_path, store); res = {"ok": True}
            self.log_tools.log(f"[tool-ret ] {json.dumps(res, ensure_ascii=False)}"); return res

        if name == "add_phrase":
            w= args.get("word", ""); ph = args.get("phrase", ""); mzh = args.get("meaning_zh", "") or ""
            idx = find_idx(w)
            if idx == -1:
                res= {"ok": False, "error": "not found"}
            else:
                e = norm_entry(store["entries"][idx])
                if not any((p.get("phrase", "").lower() == (ph or "").lower()) for p in e["phrases"]):
                    e["phrases"].append({"phrase": ph, "meaning_zh": mzh})
                store["entries"][idx]= e; dump_json_atomic(store_path, store); res = {"ok": True}
            self.log_tools.log(f"[tool-ret ] {json.dumps(res, ensure_ascii=False)}"); return res

        if name == "search_words":
            q= (args.get("query", "") or "").lower(); tg = args.get("tag", "") or ""; limit = int(args.get("limit", 20))
            out = []
            for e in store.get("entries", []):
                if q and q not in (e.get("word", "").lower()): continue
                if tg and tg not in (e.get("tags") or []): continue
                out.append({"word": e.get("word", ""), "meaning_zh": e.get(
                    "meaning_zh", ""), "tags": e.get("tags", [])})
                if len(out) >= limit: break
            res = {"items": out}; self.log_tools.log(f"[tool-ret ] {json.dumps(res, ensure_ascii=False)}"); return res

        if name == "set_attr":
            w= args.get("word", ""); k = args.get("key", ""); v = args.get("value", None)
            idx = find_idx(w)
            if idx == -1:
                res= {"ok": False, "error": "not found"}
            else:
                e= norm_entry(store["entries"][idx]); e[k] = v
                store["entries"][idx]= e; dump_json_atomic(store_path, store); res = {"ok": True}
            self.log_tools.log(f"[tool-ret ] {json.dumps(res, ensure_ascii=False)}"); return res

        # ---- æ–°å¢ï¼šåŠ æƒæŠ½æ ·æµ‹éªŒ ----
        if name == "sample_study_items":
            k = int(args.get("k", 20))
            min_gap = float(args.get("min_days_gap", 1.0))
            items = [norm_entry(e) for e in store.get("entries", [])]
            if not items:
                res = {"ok": False, "error": "empty store"}
                self.log_tools.log(f"[tool-ret ] {json.dumps(res, ensure_ascii=False)}"); return res
            pool = anti_repeat_filter(items, min_days_gap=min_gap)
            chosen = weighted_sample_without_replacement(pool, k)
            # æ ‡è®°è°ƒåº¦å¹¶å†™å›
            words = []
            for e in chosen:
                mark_scheduled(e)
                words.append({
                    "word": e.get("word", ""),
                    "meaning_zh": e.get("meaning_zh", ""),
                    "pos": e.get("pos", ""),
                    "phrases": e.get("phrases", []),
                    "example": e.get("example", {"en": "", "zh": ""})
                })
            # å†™å› entriesï¼ˆé€šè¿‡ word åŒ¹é…ï¼‰
            word2idx = {(items[i].get("word") or "").lower(): i for i in range(len(items))}
            for w in chosen:
                key = (w.get("word") or "").lower()
                idx = word2idx.get(key, -1)
                if idx != -1:
                    store["entries"][idx] = w
            dump_json_atomic(store_path, store)
            res = {"ok": True, "k": len(words), "items": words}
            self.log_tools.log(f"[tool-ret ] {json.dumps(res, ensure_ascii=False)}"); return res

        # ---- æ–°å¢ï¼šæ›´æ–° SRS ----
        if name == "update_srs":
            w= args.get("word", ""); score = float(args.get("score_0_1", 0.0))
            idx = find_idx(w)
            if idx == -1:
                res= {"ok": False, "error": "not found"}
            else:
                e = norm_entry(store["entries"][idx])
                e["srs"] = update(ensure(e.get("srs") or {}), score)
                store["entries"][idx]= e; dump_json_atomic(store_path, store); res = {"ok": True, "next_due": e["srs"]["next_due"]}
            self.log_tools.log(f"[tool-ret ] {json.dumps(res, ensure_ascii=False)}"); return res

        if name == "propose_words_from_text":
            cands= args.get("candidates", [])
            res = {"ok": True, "count": len(cands)}; self.log_tools.log(f"[tool-ret ] {json.dumps(res, ensure_ascii=False)}"); return res

        res = {"ok": False, "error": f"unknown tool {name}"}; self.log_tools.log(f"[tool-ret ] {json.dumps(res, ensure_ascii=False)}"); return res

    # ---- Chat å¾ªç¯ï¼ˆå·²ä¿®å¤ tool_calls ä¸¥æ ¼è§„èŒƒ & ä¼šè¯æŒä¹…åŒ– & ä¸Šä¸‹æ–‡è£å‰ªï¼‰----
    def _chat_send(self):
        content = (self._input_get() or "").strip()
        if not content:
            # ä¿æŒç„¦ç‚¹ï¼Œä½“éªŒæ›´é¡ºæ»‘
            try:
                self.txt_input.focus_set()
            except Exception:
                pass
            return

        # ç¡®ä¿è¯åº“è·¯å¾„å·²é€‰æ‹©
        try:
            _ = _must_pick_store_or_raise(self.e_store)
        except Exception as ex:
            messagebox.showerror("é”™è¯¯", str(ex))
            try:
                self.txt_input.focus_set()
            except Exception:
                pass
            return

        # æ¸…ç©ºè¾“å…¥ & é‡ç½®é«˜åº¦ & èšç„¦
        self._input_clear()
        try:
            self.txt_input.focus_set()
        except Exception:
            pass

        # å°†ç”¨æˆ·æ¶ˆæ¯å†™å…¥èŠå¤©çª—å£
        self.txt_chat.insert("end", f"\n[ä½ ] {content}\n")
        self.txt_chat.see("end")

        def job(progress, log):
            # å‰ªè£ä¸Šä¸‹æ–‡é•¿åº¦ï¼ˆé˜²ä¸Šä¸‹æ–‡è¿‡é•¿ï¼‰

            def _trim_messages(messages, max_len=60):
                return messages[-max_len:]

            messages = _trim_messages(
                self.chat_history + [{"role": "user", "content": content}], max_len=60)

            # å·¥å…·å¾ªç¯ï¼ˆä¸ä½ å½“å‰ç‰ˆæœ¬ä¿æŒä¸€è‡´ï¼Œå« tool_calls è§„èŒƒä¿®å¤ï¼‰
            for _round in range(10):
                resp = self.client.chat.completions.create(
                    model=MODEL_NAME, temperature=0.2,
                    messages=messages, tools=self.tools, tool_choice="auto"
                )
                msg = resp.choices[0].message
                tool_calls = getattr(msg, "tool_calls", None)

                if not tool_calls:
                    final_text = msg.content or "(æ— å›å¤)"
                    messages.append(
                        {"role": "assistant", "content": final_text})
                    self.chat_history = messages
                    # è‡ªåŠ¨ä¿å­˜å¿«ç…§ï¼ˆè‹¥å¼€å¯äº†ä¼šè¯æ–‡ä»¶ï¼‰
                    if self.current_chat_path:
                        self.current_chat_path.write_text(
                            json.dumps(self.chat_history, ensure_ascii=False, indent=2), encoding="utf-8"
                        )
                    return final_text

                assistant_msg = {
                    "role": "assistant",
                    "content": msg.content,
                    "tool_calls": [{
                        "id": tc.id,
                        "type": "function",
                        "function": {"name": tc.function.name, "arguments": tc.function.arguments or "{}"}
                    } for tc in tool_calls]
                }
                messages.append(assistant_msg)

                for tc in tool_calls:
                    try:
                        args = json.loads(tc.function.arguments or "{}")
                    except Exception:
                        args = {}
                    result = self._apply_tool(tc.function.name, args)
                    messages.append({
                        "role": "tool",
                        "tool_call_id": tc.id,
                        "name": tc.function.name,
                        "content": json.dumps(result, ensure_ascii=False)
                    })

            self.chat_history = messages
            return "ï¼ˆå·¥å…·è°ƒç”¨è½®æ¬¡è¿‡å¤šï¼Œå·²åœæ­¢ã€‚è¯·é‡è¯•æˆ–ç®€åŒ–è¯·æ±‚ã€‚ï¼‰"

        def done(text):
            self.txt_chat.insert("end", f"[åŠ©æ‰‹] {text}\n")
            self.txt_chat.see("end")
            # ä¿æŒè¾“å…¥ç„¦ç‚¹ï¼ŒEnter èƒ½ç»§ç»­å‘
            try:
                self.txt_input.focus_set()
            except Exception:
                pass

        Worker(job, on_done=done, on_log=self.log_tools.log).start()

    # ---------------- Extract ----------------ï¼ˆä¿æŒä¸å˜ï¼Œç•¥ï¼‰
    def _build_extract(self):
        f = self.tab_extract
        self.e_pdf = LineEntry(f, "PDF æ–‡ä»¶"); self.e_pdf.pack(fill="x", padx=10, pady=6)
        self.e_out = LineEntry(f, "è¾“å‡º JSON"); self.e_out.pack(fill="x", padx=10, pady=6)
        self.e_workers = LineEntry(f, "å¹¶è¡Œè¿›ç¨‹æ•°"); self.e_workers.set("4"); self.e_workers.pack(fill="x", padx=10, pady=6)

        conf = ttk.LabelFrame(f, text="å¸ƒå±€å‚æ•°ï¼ˆå¯è°ƒï¼‰"); conf.pack(fill="x", padx=10, pady=6)
        self.vars = {}
        for k in ["word_box_w","meaning_box_w","row_h","left_x0","left_y0","right_x0","right_y0","rows_per_page","number_w"]:
            fr = ttk.Frame(conf); fr.pack(fill="x", padx=6, pady=2)
            ttk.Label(fr, text=k, width=16).pack(side="left")
            v = tk.StringVar(value=str(DEFAULT_LAYOUT[k])); self.vars[k]=v
            ttk.Entry(fr, textvariable=v, width=12).pack(side="left")
        btns = ttk.Frame(f); btns.pack(fill="x", padx=10, pady=6)
        ttk.Button(btns, text="é€‰æ‹© PDF", command=self._pick_pdf).pack(side="left")
        ttk.Button(btns, text="é€‰æ‹©è¾“å‡º", command=self._pick_json_out).pack(side="left")
        ttk.Button(btns, text="è¿è¡Œæå–", command=self._run_extract).pack(side="left")
        self.pb1 = ProgBar(f); self.pb1.pack(padx=10, pady=6)
        self.log1 = LogBox(f); self.log1.pack(fill="both", expand=True, padx=10, pady=6)

    def _pick_pdf(self):
        p = filedialog.askopenfilename(title="é€‰æ‹© PDF", filetypes=[("PDF",".pdf")])
        if p: self.e_pdf.set(p)
    def _pick_json_out(self):
        p = filedialog.asksaveasfilename(title="ä¿å­˜ä¸º JSON", defaultextension=".json", filetypes=[("JSON",".json")])
        if p: self.e_out.set(p)

    def _run_extract(self):
        try:
            pdf = Path(self.e_pdf.get()); out = Path(self.e_out.get())
            layout = {k:int(self.vars[k].get()) for k in self.vars}
            workers = max(1, int(self.e_workers.get()))
        except Exception:
            messagebox.showerror("é”™è¯¯","å‚æ•°ä¸åˆæ³•"); return
        def job(progress, log):
            log(f"Extracting from {pdf} with {workers} processes...")
            rows = extract_pdf(pdf, layout, workers=workers, progress_cb=progress)
            payload = {"meta":{"source":str(pdf.resolve()),"count":len(rows)},
                       "entries": rows}
            dump_json_atomic(out, payload)
            log(f"âœ“ Saved {len(rows)} entries -> {out}")
            return out
        Worker(job, on_log=self.log1.log, on_progress=lambda d,t:self.pb1.update_ratio(d,t)).start()

    # ---------------- Enrich ----------------ï¼ˆä¿æŒä¸å˜ï¼Œç•¥ï¼‰
    def _build_enrich(self):
        f = self.tab_enrich
        self.e_in  = LineEntry(f, "è¾“å…¥ JSON"); self.e_in.pack(fill="x", padx=10, pady=6)
        self.e_out2= LineEntry(f, "è¾“å‡º JSON(enriched)"); self.e_out2.pack(fill="x", padx=10, pady=6)
        fr = ttk.Frame(f); fr.pack(fill="x", padx=10, pady=6)
        ttk.Label(fr, text="batch_size").pack(side="left"); self.v_batch=tk.StringVar(value=str(DEFAULT_BATCH_SIZE))
        ttk.Entry(fr, textvariable=self.v_batch, width=6).pack(side="left", padx=6)
        ttk.Label(fr, text="checkpoint_every").pack(side="left"); self.v_ck=tk.StringVar(value=str(DEFAULT_CHECKPOINT_EVERY))
        ttk.Entry(fr, textvariable=self.v_ck, width=6).pack(side="left", padx=6)
        self.only_fix = tk.BooleanVar(value=False)
        ttk.Checkbutton(fr, text="ä»…ä¿®å¤ç¼ºå¤±é‡Šä¹‰", variable=self.only_fix).pack(side="left", padx=12)
        btns = ttk.Frame(f); btns.pack(fill="x", padx=10, pady=6)
        ttk.Button(btns, text="é€‰æ‹©è¾“å…¥", command=lambda:self._pick_json(self.e_in)).pack(side="left")
        ttk.Button(btns, text="é€‰æ‹©è¾“å‡º", command=self._pick_json_out2).pack(side="left")
        ttk.Button(btns, text="å¼€å§‹ Enrich", command=self._run_enrich).pack(side="left")
        self.txt_article = tk.Text(f, height=8, wrap="word"); self.txt_article.pack(fill="x", padx=10, pady=6)
        ttk.Button(f, text="ä»ä¸Šæ–‡è‡ªåŠ¨æè¯å¹¶åŠ å…¥è¯åº“ï¼ˆå…¥ enriched.json è‰ç¨¿ï¼‰", command=self._propose_into_enriched).pack(padx=10, pady=4)
        self.pb2 = ProgBar(f); self.pb2.pack(padx=10, pady=6)
        self.log2 = LogBox(f); self.log2.pack(fill="both", expand=True, padx=10, pady=6)

    def _pick_json_out2(self):
        p = filedialog.asksaveasfilename(title="ä¿å­˜ä¸º JSON", defaultextension=".json", filetypes=[("JSON",".json")])
        if p: self.e_out2.set(p)

    def _run_enrich(self):
        try:
            in_p = Path(self.e_in.get()); out_p = Path(self.e_out2.get())
            bs = max(1, int(self.v_batch.get())); ck = max(0, int(self.v_ck.get()))
            only_fix = bool(self.only_fix.get())
        except Exception:
            messagebox.showerror("é”™è¯¯","å‚æ•°ä¸åˆæ³•"); return
        def job(progress, log):
            log(f"Enrich: input={in_p} -> {out_p}  batch={bs}  ck={ck}  only_fix={only_fix}")
            res = enrich_file(in_p, out_p, batch_size=bs, checkpoint_every=ck,
                              only_fix_missing=only_fix, progress_cb=progress, show_tqdm=False)
            log(f"âœ“ Enriched -> {res}")
            return res
        Worker(job, on_log=self.log2.log, on_progress=lambda d,t:self.pb2.update_ratio(d,t)).start()

    def _propose_into_enriched(self):
        article = self.txt_article.get("1.0","end").strip()
        if not article:
            messagebox.showinfo("æç¤º","è¯·å…ˆåœ¨æ–‡æœ¬æ¡†ç²˜è´´æ–‡ç« å†…å®¹"); return
        try:
            out_p = Path(self.e_out2.get())
            if not out_p.exists():
                messagebox.showerror("é”™è¯¯","è¯·å…ˆå®Œæˆä¸€æ¬¡ enrichï¼Œç¡®ä¿ enriched.json å·²åˆ›å»º"); return
            store = load_json(out_p)
        except Exception:
            messagebox.showerror("é”™è¯¯","è¯»å– enriched.json å¤±è´¥"); return
        def job(progress, log):
            log("LLM æ­£åœ¨ä»æ–‡ç« æè¯...")
            cands = propose_from_text(article)
            if not cands:
                log("æœªè·å¾—å€™é€‰è¯"); return
            exists = { (e.get('word') or '').lower() for e in store.get("entries",[]) }
            appended = 0
            for c in cands:
                w = (c.get("word") or "").strip()
                if not w or w.lower() in exists: continue
                store["entries"].append({"word":w, "meaning_zh":"", "pos":"", "synonyms_en":[], "phrases":[],
                                         "example":{"en":"","zh":""}, "confusions":[], "model_notes":"", "srs":dict(DEFAULT_SRS)})
                exists.add(w.lower()); appended += 1
            store.setdefault("meta",{}); store["meta"]["count"]=len(store["entries"])
            dump_json_atomic(out_p, store)
            log(f"å·²å†™å…¥ {appended} ä¸ªå€™é€‰åˆ° {out_p}ï¼ˆéšååœ¨ Enrich é¢æ¿ä¿®å¤é‡Šä¹‰ï¼‰")
        Worker(job, on_log=self.log2.log).start()

    # ---------------- Study ----------------ï¼ˆä¿æŒä½ ä¹‹å‰çš„â€œè®°å¾—ï¼Ÿ+é€ å¥â€æµç¨‹ä¸å˜ï¼‰
    def _build_study(self):
        f = self.tab_study
        self.e_store2 = LineEntry(f, "è¯åº“ JSON (enriched)"); self.e_store2.pack(fill="x", padx=10, pady=6)
        btns = ttk.Frame(f); btns.pack(fill="x", padx=10, pady=6)
        ttk.Button(btns, text="é€‰æ‹©è¯åº“", command=lambda:self._pick_json(self.e_store2)).pack(side="left")
        ttk.Button(btns, text="å¼€å§‹ä¸€è½®å¤ä¹ ", command=self._start_study).pack(side="left")
        self.frm_q = ttk.LabelFrame(f, text="é¢˜ç›®"); self.frm_q.pack(fill="x", padx=10, pady=6)

        self.lbl_q = ttk.Label(self.frm_q, text="å°šæœªå¼€å§‹"); self.lbl_q.pack(anchor="w", padx=8, pady=8)
        ans_row = ttk.Frame(self.frm_q); ans_row.pack(fill="x", padx=8, pady=4)
        ttk.Label(ans_row, text="æ˜¯å¦è®°å¾—è¯¥è¯ï¼Ÿ(y/n)").pack(side="left")
        self.var_mem = tk.StringVar(); ttk.Entry(ans_row, textvariable=self.var_mem, width=6).pack(side="left", padx=6)
        self.var_sent = tk.StringVar()
        ttk.Label(self.frm_q, text="è¯·ç”¨è¯¥è¯å†™ä¸€ä¸ªè‹±æ–‡å¥å­ï¼š").pack(anchor="w", padx=8)
        ttk.Entry(self.frm_q, textvariable=self.var_sent, width=90).pack(fill="x", padx=8, pady=4)
        ttk.Button(self.frm_q, text="æäº¤", command=self._submit_answer).pack(padx=8, pady=4)

        self.log3 = LogBox(f); self.log3.pack(fill="both", expand=True, padx=10, pady=6)
        self.study_queue = []; self.cur = None; self.store = None; self.store_path = None

    def _start_study(self):
        p = (self.e_store2.get() or "").strip()
        if not p:
            messagebox.showerror("é”™è¯¯","è¯·å…ˆé€‰æ‹© enriched.json"); return
        self.store_path = Path(p)
        if not self.store_path.exists():
            messagebox.showerror("é”™è¯¯","è¯åº“ä¸å­˜åœ¨"); return
        self.store = load_json(self.store_path)
        items = self.store.get("entries",[])
        if not items:
            messagebox.showerror("é”™è¯¯","è¯åº“ä¸ºç©º"); return
        # ç”¨ä¸ Chat ç›¸åŒçš„æŠ½æ ·é€»è¾‘ï¼Œä¿è¯è¦†ç›–
        pool = anti_repeat_filter(items, min_days_gap=1.0)
        chosen = weighted_sample_without_replacement(pool, 15)
        self.study_queue = chosen
        self._next_question()

    def _next_question(self):
        if not self.study_queue:
            self.lbl_q.config(text="æœ¬è½®å®Œæˆ ğŸ‰"); return
        self.cur = self.study_queue.pop(0)
        self.lbl_q.config(text=f"å›å¿†é‡Šä¹‰ï¼š{self.cur.get('word','')}")
        self.var_mem.set(""); self.var_sent.set("")

    def _submit_answer(self):
        if not self.cur: return
        remembered = (self.var_mem.get().strip().lower() in ["y","yes","æ˜¯","è®°å¾—"])
        mzh = self.cur.get("meaning_zh",""); phs = self.cur.get("phrases",[]); ex=(self.cur.get("example") or {})
        self.log3.log(f"[å‚è€ƒé‡Šä¹‰] {mzh}")
        if phs: self.log3.log("[å¸¸ç”¨è¯ç»„] " + "; ".join([f"{p.get('phrase')}({p.get('meaning_zh','')})" for p in phs[:6]]))
        if ex.get("en"): self.log3.log(f"[å‚è€ƒä¾‹å¥] {ex.get('en')} ({ex.get('zh')})")

        sent = self.var_sent.get().strip()
        if sent:
            result = grade_with_llm("example_usage", {
                "word": self.cur.get("word",""),
                "meaning_zh": mzh, "pos": self.cur.get("pos",""),
                "synonyms_en": self.cur.get("synonyms_en",[]),
                "phrases": phs, "example": ex,
                "confusions": self.cur.get("confusions",[]),
                "model_notes": self.cur.get("model_notes","")
            }, sent)
            self.log3.log(json.dumps(result, ensure_ascii=False, indent=2))
            score = float(result.get("score_0_1", 0.0))
        else:
            score = 0.8 if remembered else 0.3
            self.log3.log(f"[è‡ªè¯„] remembered={remembered} => score={score}")

        # æ›´æ–° SRS
        srs0 = ensure(self.cur.get("srs") or {})
        self.cur["srs"] = update(srs0, score)
        # å†™å›æ–‡ä»¶
        for i, e in enumerate(self.store["entries"]):
            if (e.get("word") or "").lower() == (self.cur.get("word") or "").lower():
                self.store["entries"][i] = self.cur; break
        dump_json_atomic(self.store_path, self.store)
        self._next_question()
def run():
    App().mainloop()

if __name__ == "__main__":
    run()
